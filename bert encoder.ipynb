{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41bc160f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an old person kisses a young person someone is doing it over\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/opt/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialze the model\n",
      "model finished running\n",
      "tensor([[[-4.6980e-01, -7.0262e-02, -1.7950e-01,  ..., -5.9425e-01,\n",
      "          -6.1782e-02,  7.2648e-01],\n",
      "         [-1.0975e+00,  3.3036e-01, -2.9822e-01,  ..., -8.9204e-02,\n",
      "          -3.7921e-01,  6.4196e-01],\n",
      "         [-1.4957e-02,  1.3440e-01,  1.5617e+00,  ..., -8.5316e-02,\n",
      "          -1.0064e-01, -7.5099e-02],\n",
      "         ...,\n",
      "         [-8.4801e-02, -1.0627e-01,  6.5195e-01,  ..., -5.9656e-01,\n",
      "          -1.4972e-01,  3.6755e-01],\n",
      "         [-3.8373e-01, -3.8088e-01,  5.1599e-01,  ..., -4.2659e-01,\n",
      "          -4.4540e-02,  2.1065e-01],\n",
      "         [-3.7208e-02, -7.2215e-02,  5.9798e-01,  ..., -4.9822e-01,\n",
      "          -1.1695e-01,  2.3800e-01]],\n",
      "\n",
      "        [[-4.1609e-01, -1.4339e-01, -1.7724e-01,  ..., -5.5626e-01,\n",
      "          -1.0671e-01,  7.6768e-01],\n",
      "         [-1.1489e+00,  1.8876e-01, -8.1531e-02,  ..., -4.7860e-01,\n",
      "          -3.5798e-01,  5.2645e-01],\n",
      "         [-4.7970e-01, -4.8129e-01,  7.8489e-01,  ..., -5.9667e-01,\n",
      "          -2.5143e-01, -9.0400e-01],\n",
      "         ...,\n",
      "         [-8.4096e-02, -1.3862e-01,  6.0388e-01,  ..., -5.5566e-01,\n",
      "          -1.4932e-01,  3.4813e-01],\n",
      "         [-4.5868e-01, -4.6121e-01,  4.4909e-01,  ..., -3.6642e-01,\n",
      "          -3.4806e-02,  2.0678e-01],\n",
      "         [-7.4557e-02, -1.0420e-01,  5.5013e-01,  ..., -4.4146e-01,\n",
      "          -1.0880e-01,  2.4704e-01]],\n",
      "\n",
      "        [[-2.3555e-01, -4.8462e-02,  2.6825e-01,  ..., -4.0141e-01,\n",
      "           1.7472e-02,  3.6651e-01],\n",
      "         [-1.0906e+00, -9.8401e-01,  2.2081e-01,  ..., -1.0158e-01,\n",
      "           1.0161e+00, -2.7421e-01],\n",
      "         [-5.3719e-01,  2.3010e-01,  1.1481e+00,  ..., -6.5122e-01,\n",
      "           5.3039e-01, -8.1561e-01],\n",
      "         ...,\n",
      "         [-4.9115e-01,  1.1087e-02,  4.7085e-01,  ..., -1.8187e-01,\n",
      "          -1.3358e-01,  2.4721e-01],\n",
      "         [-7.9109e-01, -7.0716e-02,  4.6656e-01,  ...,  2.9616e-02,\n",
      "           5.7358e-02,  1.2494e-01],\n",
      "         [-5.4957e-01,  4.6702e-02,  4.9137e-01,  ..., -1.1093e-01,\n",
      "           3.1394e-04,  1.4118e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.3893e-01, -3.7002e-02, -3.3902e-01,  ..., -1.5986e-01,\n",
      "           4.3886e-01,  3.2287e-01],\n",
      "         [ 3.1436e-01,  6.7477e-02, -2.8526e-01,  ...,  6.5858e-02,\n",
      "           5.5332e-01, -1.7528e-01],\n",
      "         [-1.5596e-01, -4.4186e-01,  1.2113e-01,  ..., -3.9170e-01,\n",
      "           1.0559e-01,  1.5613e-01],\n",
      "         ...,\n",
      "         [-4.5318e-01, -3.5490e-01, -2.8326e-02,  ...,  1.9308e-01,\n",
      "           1.0700e-01, -2.6365e-01],\n",
      "         [-1.2508e-01, -1.8391e-01,  1.7046e-01,  ...,  4.6328e-02,\n",
      "           1.5989e-03, -2.9268e-01],\n",
      "         [-2.9982e-01, -2.3150e-01,  6.2438e-02,  ...,  1.2247e-01,\n",
      "           1.8606e-02, -2.9982e-01]],\n",
      "\n",
      "        [[ 3.5467e-01,  6.7889e-01,  1.3440e-01,  ..., -2.7055e-01,\n",
      "           2.0662e-01,  2.5702e-01],\n",
      "         [-3.8884e-03,  6.1648e-01,  3.0051e-01,  ..., -3.4971e-01,\n",
      "           4.3132e-01,  1.4848e-01],\n",
      "         [ 2.6645e-01,  6.2890e-01,  1.7622e-01,  ...,  3.5322e-01,\n",
      "           4.2532e-01,  3.0095e-01],\n",
      "         ...,\n",
      "         [ 1.7501e-01,  1.5385e-01,  4.1285e-01,  ..., -1.3120e-02,\n",
      "           1.3727e-01, -3.8251e-02],\n",
      "         [ 2.7621e-01,  2.0738e-01,  4.6109e-01,  ...,  1.9406e-02,\n",
      "          -4.6305e-02, -1.9147e-01],\n",
      "         [ 5.7798e-01,  3.3701e-01,  4.7216e-01,  ...,  7.6057e-02,\n",
      "           1.8190e-01, -3.5520e-02]],\n",
      "\n",
      "        [[ 2.4806e-01,  8.2576e-01,  1.1892e-01,  ..., -3.6900e-01,\n",
      "           8.5041e-02,  3.6976e-01],\n",
      "         [ 1.3072e-01,  7.9264e-01, -7.2731e-02,  ..., -2.8626e-01,\n",
      "           1.4764e-01,  4.1761e-01],\n",
      "         [ 3.6062e-01,  5.6498e-01,  1.6775e-01,  ...,  5.2334e-01,\n",
      "           1.3315e-01,  2.2628e-01],\n",
      "         ...,\n",
      "         [ 4.1317e-01,  4.3908e-01,  6.2217e-01,  ..., -1.3560e-01,\n",
      "          -6.4020e-03,  1.1252e-01],\n",
      "         [ 4.6775e-01,  3.6121e-01,  6.4809e-01,  ..., -5.7814e-02,\n",
      "           9.1495e-02,  7.5160e-02],\n",
      "         [-7.5059e-02, -7.8236e-02,  2.7615e-01,  ...,  2.9971e-01,\n",
      "           4.6265e-01, -1.2290e-01]]]) tensor([[-0.9254, -0.4646, -0.8964,  ..., -0.6651, -0.7466,  0.8544],\n",
      "        [-0.9205, -0.4420, -0.8531,  ..., -0.6286, -0.7342,  0.8458],\n",
      "        [-0.4540,  0.0288,  0.9271,  ...,  0.8723, -0.3831,  0.6468],\n",
      "        ...,\n",
      "        [-0.8223, -0.0658,  0.0027,  ..., -0.0705, -0.5521,  0.8257],\n",
      "        [-0.9426, -0.3464, -0.6132,  ..., -0.0482, -0.7051,  0.9503],\n",
      "        [-0.9436, -0.3202, -0.6139,  ..., -0.0288, -0.7327,  0.9589]])\n",
      "torch.Size([800, 20, 768])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "sentence_lis=[]\n",
    "# 打开JSONL文件\n",
    "with open('examples2.jsonl', 'r') as f:\n",
    "    # 遍历每一行\n",
    "    for line in f:\n",
    "        # 解析JSON对象\n",
    "        data = json.loads(line)\n",
    "        # 遍历每个字典\n",
    "        sentence_lis.append(data[\"caption_0\"])\n",
    "        sentence_lis.append(data[\"caption_1\"])\n",
    "print(sentence_lis[0],sentence_lis[-1])\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加载BERT tokenizer和模型\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased', \n",
    "                                  gradient_checkpointing=True,\n",
    "                                 output_hidden_states=True, \n",
    "                                   output_attentions=True)\n",
    "                                  #cls_seq_relationship_weight=False,\n",
    "                                  #cls_predictions_transform_dense_weight=False,\n",
    "                                  #cls_predictions_transform_LayerNorm_weight=False,\n",
    "                                  #cls_predictions_decoder_weight=False,\n",
    "                                  #cls_seq_relationship_bias=False,\n",
    "                                  #cls_predictions_bias=False,\n",
    "                                  #cls_predictions_transform_dense_bias=False,\n",
    "                                  #cls_predictions_transform_LayerNorm_bias=False)\n",
    "'''model.to(device)'''\n",
    "\n",
    "# Process training data\n",
    "'''text_data = training_loader['cleantext'].tolist()\n",
    "encoded_inputs = tokenizer.batch_encode_plus(text_data, return_attention_mask=True, return_tensors='pt',padding=True,truncation=True)\n",
    "input_ids = encoded_inputs['input_ids'].to(device)\n",
    "attention_mask = encoded_inputs['attention_mask'].to(device)\n",
    "labels =  training_loader['label'].tolist()\n",
    "# Create training dataset\n",
    "train_dataset = TensorDataset(input_ids, attention_mask, torch.tensor(labels,device=device))'''\n",
    "\n",
    "# 对语料进行编码\n",
    "encoded_dict = tokenizer.batch_encode_plus(\n",
    "                sentence_lis,                      # 待编码的句子列表\n",
    "                add_special_tokens=True,        # 添加特殊标记\n",
    "                max_length=20,                  # 设置最大长度\n",
    "                pad_to_max_length=True,         # 填充到最大长度\n",
    "                return_attention_mask=True,     # 返回attention mask\n",
    "                return_tensors='pt',         # 返回PyTorch张量\n",
    "           )\n",
    "print('initialze the model')\n",
    "with torch.no_grad():\n",
    "# 将编码结果输入BERT模型\n",
    "    outputs = model(encoded_dict['input_ids'], encoded_dict['attention_mask'])\n",
    "print('model finished running')\n",
    "print(outputs[0],outputs[1])\n",
    "output_tensor=outputs.last_hidden_state\n",
    "print(output_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af7a2a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29194\n",
      "tensor([11458213, 10591179,  3038666,  ...,  2103292, 10358424,  6244380])\n",
      "68802\n",
      "tensor([ 6438526,  2361444,  5869018,  ...,  9358301, 11694461,  3832401])\n",
      "tensor(1228800)\n",
      "torch.Size([800, 20, 768])\n",
      "torch.Size([800, 20, 768])\n",
      "tensor(2211960)\n",
      "tensor(1228800)\n",
      "tensor(1228800)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "#add the mask to the given tensor\n",
    "#randomly pick ten percents of the entries in the third dimension to be zero\n",
    "#is this way to mask the tensor reasonable?\n",
    "def random_zero_tensor(x,p=0.1):\n",
    "    x_1=copy.deepcopy(x)\n",
    "    seed=torch.randint(0,100000,size=(1,)).item()\n",
    "    print(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    x_flatten=x_1.view(-1)\n",
    "    num_zeros=int(len(x_flatten)*p)\n",
    "    zero_indices=torch.randperm(len(x_flatten))[:num_zeros]\n",
    "    print(zero_indices)\n",
    "    x_1.view(-1)[zero_indices]=0.0\n",
    "    return x_1,zero_indices\n",
    "\n",
    "\n",
    "masked_tensor1,zero_indice1=random_zero_tensor(output_tensor,p=0.1)\n",
    "masked_tensor2,zero_indice2=random_zero_tensor(output_tensor,p=0.1)\n",
    "\n",
    "print(torch.sum(zero_indice1!=zero_indice2))\n",
    "\n",
    "print(masked_tensor1.shape)\n",
    "print(masked_tensor2.shape)\n",
    "print(torch.sum(masked_tensor1!=masked_tensor2))\n",
    "print(torch.sum(masked_tensor1==0))\n",
    "print(torch.sum(masked_tensor2==0))\n",
    "#print(masked_tensor1[0][0][3])\n",
    "#print(masked_tensor2[0][0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "662a147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a neural network that can project a tensor of size (n,20,768) to the tensor of size(n,128)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "class mlp(nn.Module):\n",
    "    def __init__(self,input_dim1,input_dim2,output_dim):\n",
    "        super(mlp,self).__init__()\n",
    "        self.fc1=nn.Linear(input_dim1*input_dim2,1024)\n",
    "        self.fc2=nn.Linear(1024,512)\n",
    "        self.fc3=nn.Linear(512,output_dim)\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=x.view(x.size(0),-1)\n",
    "        x=self.relu(self.fc1(x))\n",
    "        x=self.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7a3be9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the network\n",
    "import torch.optim as optim\n",
    "mlp=mlp(20,768,128)\n",
    "optimizer=optim.Adam(mlp.parameters(),lr=1e-3)\n",
    "\n",
    "criterion=nn.MSELoss()\n",
    "\n",
    "n_iterations=100\n",
    "batch_size=100\n",
    "\n",
    "X_train1,X_val1=masked_tensor1[:700],masked_tensor1[700:]\n",
    "X_train2,X_val2=masked_tensor2[:700],masked_tensor2[700:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "28ab7960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005485783913172781\n",
      "7.836834161675402e-05\n",
      "iter 0 train loss 7.836834161675402e-05 valloss 1.5370151231763884e-05\n",
      "0.0004435788141563535\n",
      "6.33684020223362e-05\n",
      "iter 1 train loss 6.33684020223362e-05 valloss 4.463771347218426e-06\n",
      "9.376993693877012e-05\n",
      "1.339570527696716e-05\n",
      "iter 2 train loss 1.339570527696716e-05 valloss 2.2354502107191365e-06\n",
      "2.3895105186966248e-05\n",
      "3.4135864552808926e-06\n",
      "iter 3 train loss 3.4135864552808926e-06 valloss 1.4007528079673648e-06\n",
      "9.371206942887511e-06\n",
      "1.3387438489839302e-06\n",
      "iter 4 train loss 1.3387438489839302e-06 valloss 1.0107045227414346e-06\n",
      "4.083408839505864e-06\n",
      "5.833441199294092e-07\n",
      "iter 5 train loss 5.833441199294092e-07 valloss 8.433118523498706e-07\n",
      "1.9540439097909257e-06\n",
      "2.791491299701322e-07\n",
      "iter 6 train loss 2.791491299701322e-07 valloss 7.550287364210817e-07\n",
      "1.0063536137749907e-06\n",
      "1.437648019678558e-07\n",
      "iter 7 train loss 1.437648019678558e-07 valloss 7.047510166557913e-07\n",
      "5.472414841278805e-07\n",
      "7.81773548754115e-08\n",
      "iter 8 train loss 7.81773548754115e-08 valloss 6.746629992449016e-07\n",
      "2.995343209022394e-07\n",
      "4.279061727174849e-08\n",
      "iter 9 train loss 4.279061727174849e-08 valloss 6.5814134586617e-07\n",
      "1.612921352034391e-07\n",
      "2.30417336004913e-08\n",
      "iter 10 train loss 2.30417336004913e-08 valloss 6.500678750853695e-07\n",
      "1.0857199583824695e-07\n",
      "1.5510285119749564e-08\n",
      "iter 11 train loss 1.5510285119749564e-08 valloss 6.39260633761296e-07\n",
      "7.29634521690059e-08\n",
      "1.0423350309857987e-08\n",
      "iter 12 train loss 1.0423350309857987e-08 valloss 6.412633979380189e-07\n",
      "4.912427797876262e-08\n",
      "7.017753996966089e-09\n",
      "iter 13 train loss 7.017753996966089e-09 valloss 6.383834261214361e-07\n",
      "3.394130487777147e-08\n",
      "4.848757839681639e-09\n",
      "iter 14 train loss 4.848757839681639e-09 valloss 6.348198553496331e-07\n",
      "2.607335680693268e-08\n",
      "3.72476525813324e-09\n",
      "iter 15 train loss 3.72476525813324e-09 valloss 6.357846018545388e-07\n",
      "2.0068430472974796e-08\n",
      "2.8669186389963995e-09\n",
      "iter 16 train loss 2.8669186389963995e-09 valloss 6.343579457279702e-07\n",
      "1.6064454655406735e-08\n",
      "2.2949220936295335e-09\n",
      "iter 17 train loss 2.2949220936295335e-09 valloss 6.326442303361546e-07\n",
      "1.3279509047947613e-08\n",
      "1.8970727211353733e-09\n",
      "iter 18 train loss 1.8970727211353733e-09 valloss 6.331634381240292e-07\n",
      "1.1146669365302841e-08\n",
      "1.592381337900406e-09\n",
      "iter 19 train loss 1.592381337900406e-09 valloss 6.332944053610845e-07\n",
      "9.60438839570088e-09\n",
      "1.3720554851001258e-09\n",
      "iter 20 train loss 1.3720554851001258e-09 valloss 6.328363610919041e-07\n",
      "8.590864020163735e-09\n",
      "1.2272662885948193e-09\n",
      "iter 21 train loss 1.2272662885948193e-09 valloss 6.331449640128994e-07\n",
      "8.400488304971532e-09\n",
      "1.200069757853076e-09\n",
      "iter 22 train loss 1.200069757853076e-09 valloss 6.325003596430179e-07\n",
      "1.029283858144936e-08\n",
      "1.4704055116356228e-09\n",
      "iter 23 train loss 1.4704055116356228e-09 valloss 6.327560413410538e-07\n",
      "1.553320494451782e-08\n",
      "2.21902927778826e-09\n",
      "iter 24 train loss 2.21902927778826e-09 valloss 6.320804004644742e-07\n",
      "3.376688795242444e-08\n",
      "4.823841136060634e-09\n",
      "iter 25 train loss 4.823841136060634e-09 valloss 6.326504831122293e-07\n",
      "7.996622031214429e-08\n",
      "1.1423745758877755e-08\n",
      "iter 26 train loss 1.1423745758877755e-08 valloss 6.326328616523824e-07\n",
      "1.2138043814502453e-07\n",
      "1.7340062592146362e-08\n",
      "iter 27 train loss 1.7340062592146362e-08 valloss 6.308246724984201e-07\n",
      "1.3791890296488418e-07\n",
      "1.9702700423554883e-08\n",
      "iter 28 train loss 1.9702700423554883e-08 valloss 6.28849363693007e-07\n",
      "1.1945876110530662e-07\n",
      "1.706553730075809e-08\n",
      "iter 29 train loss 1.706553730075809e-08 valloss 6.270979611144867e-07\n",
      "7.113883526699283e-08\n",
      "1.0162690752427546e-08\n",
      "iter 30 train loss 1.0162690752427546e-08 valloss 6.246646080398932e-07\n",
      "2.9330347928180345e-08\n",
      "4.190049704025764e-09\n",
      "iter 31 train loss 4.190049704025764e-09 valloss 6.238601599761751e-07\n",
      "1.2361919488057538e-08\n",
      "1.765988498293934e-09\n",
      "iter 32 train loss 1.765988498293934e-09 valloss 6.229602718121896e-07\n",
      "1.388645642919073e-08\n",
      "1.98377948988439e-09\n",
      "iter 33 train loss 1.98377948988439e-09 valloss 6.226001119102875e-07\n",
      "2.6220865478876476e-08\n",
      "3.745837925553783e-09\n",
      "iter 34 train loss 3.745837925553783e-09 valloss 6.228844995348481e-07\n",
      "5.3893380425051873e-08\n",
      "7.699054346435981e-09\n",
      "iter 35 train loss 7.699054346435981e-09 valloss 6.203011935212999e-07\n",
      "6.208173886079749e-08\n",
      "8.868819837256784e-09\n",
      "iter 36 train loss 8.868819837256784e-09 valloss 6.221811190698645e-07\n",
      "5.99656431177209e-08\n",
      "8.5665204453887e-09\n",
      "iter 37 train loss 8.5665204453887e-09 valloss 6.174411737447372e-07\n",
      "4.216397186951326e-08\n",
      "6.023424552787609e-09\n",
      "iter 38 train loss 6.023424552787609e-09 valloss 6.198451387717796e-07\n",
      "2.36066224346132e-08\n",
      "3.3723746335161717e-09\n",
      "iter 39 train loss 3.3723746335161717e-09 valloss 6.161428132145375e-07\n",
      "1.284922213073969e-08\n",
      "1.8356031615342415e-09\n",
      "iter 40 train loss 1.8356031615342415e-09 valloss 6.177235150062188e-07\n",
      "8.19772694171661e-09\n",
      "1.1711038488166586e-09\n",
      "iter 41 train loss 1.1711038488166586e-09 valloss 6.159797294458258e-07\n",
      "7.64833618660532e-09\n",
      "1.0926194552293315e-09\n",
      "iter 42 train loss 1.0926194552293315e-09 valloss 6.164571573208377e-07\n",
      "9.975659409633408e-09\n",
      "1.4250942013762013e-09\n",
      "iter 43 train loss 1.4250942013762013e-09 valloss 6.16231602634798e-07\n",
      "1.5615050585893187e-08\n",
      "2.230721512270455e-09\n",
      "iter 44 train loss 2.230721512270455e-09 valloss 6.155382266115339e-07\n",
      "2.7327077489758267e-08\n",
      "3.90386821282261e-09\n",
      "iter 45 train loss 3.90386821282261e-09 valloss 6.163197667774512e-07\n",
      "5.195347441144804e-08\n",
      "7.421924915921149e-09\n",
      "iter 46 train loss 7.421924915921149e-09 valloss 6.140407435850648e-07\n",
      "1.0296153618583048e-07\n",
      "1.4708790883690069e-08\n",
      "iter 47 train loss 1.4708790883690069e-08 valloss 6.160059342619206e-07\n",
      "1.9883538016074453e-07\n",
      "2.840505430867779e-08\n",
      "iter 48 train loss 2.840505430867779e-08 valloss 6.093823117225838e-07\n",
      "3.39721054842812e-07\n",
      "4.853157926325886e-08\n",
      "iter 49 train loss 4.853157926325886e-08 valloss 6.131220970928553e-07\n",
      "4.0926536826191295e-07\n",
      "5.846648118027328e-08\n",
      "iter 50 train loss 5.846648118027328e-08 valloss 5.979856041449239e-07\n",
      "2.6483201054361416e-07\n",
      "3.7833144363373453e-08\n",
      "iter 51 train loss 3.7833144363373453e-08 valloss 6.020602540957043e-07\n",
      "1.2762559720158606e-07\n",
      "1.823222817165515e-08\n",
      "iter 52 train loss 1.823222817165515e-08 valloss 5.885832479179953e-07\n",
      "1.228132759933942e-07\n",
      "1.7544753713342028e-08\n",
      "iter 53 train loss 1.7544753713342028e-08 valloss 5.884820097890042e-07\n",
      "1.0815982420808723e-07\n",
      "1.5451403458298174e-08\n",
      "iter 54 train loss 1.5451403458298174e-08 valloss 5.850708362231671e-07\n",
      "7.754824338235267e-08\n",
      "1.1078320483193238e-08\n",
      "iter 55 train loss 1.1078320483193238e-08 valloss 5.796946993541496e-07\n",
      "4.5436099327389456e-08\n",
      "6.490871332484208e-09\n",
      "iter 56 train loss 6.490871332484208e-09 valloss 5.790968202745717e-07\n",
      "1.964976803492391e-08\n",
      "2.807109719274844e-09\n",
      "iter 57 train loss 2.807109719274844e-09 valloss 5.768932851424324e-07\n",
      "8.813702656595979e-09\n",
      "1.2591003795137112e-09\n",
      "iter 58 train loss 1.2591003795137112e-09 valloss 5.766087838310341e-07\n",
      "5.840327776951426e-09\n",
      "8.343325395644894e-10\n",
      "iter 59 train loss 8.343325395644894e-10 valloss 5.753660161644802e-07\n",
      "5.374736211649633e-09\n",
      "7.678194588070905e-10\n",
      "iter 60 train loss 7.678194588070905e-10 valloss 5.763227477473265e-07\n",
      "5.737831099139612e-09\n",
      "8.196901570199446e-10\n",
      "iter 61 train loss 8.196901570199446e-10 valloss 5.746189799538115e-07\n",
      "6.841694766279716e-09\n",
      "9.77384966611388e-10\n",
      "iter 62 train loss 9.77384966611388e-10 valloss 5.762072419202013e-07\n",
      "9.087612440339399e-09\n",
      "1.2982303486199142e-09\n",
      "iter 63 train loss 1.2982303486199142e-09 valloss 5.740305368817644e-07\n",
      "1.2935607252018144e-08\n",
      "1.847943893145449e-09\n",
      "iter 64 train loss 1.847943893145449e-09 valloss 5.760250019193336e-07\n",
      "1.9261134909243083e-08\n",
      "2.7515907013204402e-09\n",
      "iter 65 train loss 2.7515907013204402e-09 valloss 5.730770453737932e-07\n",
      "2.9445924809579083e-08\n",
      "4.206560687082726e-09\n",
      "iter 66 train loss 4.206560687082726e-09 valloss 5.756316454608168e-07\n",
      "4.54204567290617e-08\n",
      "6.488636675580242e-09\n",
      "iter 67 train loss 6.488636675580242e-09 valloss 5.710686536986032e-07\n",
      "6.843022504199325e-08\n",
      "9.775746434570465e-09\n",
      "iter 68 train loss 9.775746434570465e-09 valloss 5.743409019487444e-07\n",
      "9.703760639467873e-08\n",
      "1.3862515199239818e-08\n",
      "iter 69 train loss 1.3862515199239818e-08 valloss 5.670549398928415e-07\n",
      "1.203054722509478e-07\n",
      "1.7186496035849685e-08\n",
      "iter 70 train loss 1.7186496035849685e-08 valloss 5.703045644622762e-07\n",
      "1.222645522602761e-07\n",
      "1.7466364608610874e-08\n",
      "iter 71 train loss 1.7466364608610874e-08 valloss 5.610803555100574e-07\n",
      "9.244671872465915e-08\n",
      "1.3206674103522736e-08\n",
      "iter 72 train loss 1.3206674103522736e-08 valloss 5.638488005388353e-07\n",
      "5.138436165452731e-08\n",
      "7.340623093503902e-09\n",
      "iter 73 train loss 7.340623093503902e-09 valloss 5.568412007050938e-07\n",
      "2.50623060082944e-08\n",
      "3.5803294297563427e-09\n",
      "iter 74 train loss 3.5803294297563427e-09 valloss 5.591440412899829e-07\n",
      "1.57143507095725e-08\n",
      "2.244907244224643e-09\n",
      "iter 75 train loss 2.244907244224643e-09 valloss 5.549425168283051e-07\n",
      "1.1826743140375129e-08\n",
      "1.6895347343393041e-09\n",
      "iter 76 train loss 1.6895347343393041e-09 valloss 5.573298267336213e-07\n",
      "8.805323581384528e-09\n",
      "1.2579033687692182e-09\n",
      "iter 77 train loss 1.2579033687692182e-09 valloss 5.537568199542875e-07\n",
      "6.58278853649108e-09\n",
      "9.403983623558686e-10\n",
      "iter 78 train loss 9.403983623558686e-10 valloss 5.565714218391804e-07\n",
      "5.261168833925467e-09\n",
      "7.515955477036382e-10\n",
      "iter 79 train loss 7.515955477036382e-10 valloss 5.531205715669785e-07\n",
      "4.581205192977222e-09\n",
      "6.544578847110318e-10\n",
      "iter 80 train loss 6.544578847110318e-10 valloss 5.560390263781301e-07\n",
      "4.342852744088077e-09\n",
      "6.204075348697253e-10\n",
      "iter 81 train loss 6.204075348697253e-10 valloss 5.528228825824044e-07\n",
      "4.416725207789796e-09\n",
      "6.309607439699708e-10\n",
      "iter 82 train loss 6.309607439699708e-10 valloss 5.556079827329086e-07\n",
      "4.783079710080074e-09\n",
      "6.832971014400105e-10\n",
      "iter 83 train loss 6.832971014400105e-10 valloss 5.525124038285867e-07\n",
      "5.476119557812353e-09\n",
      "7.823027939731933e-10\n",
      "iter 84 train loss 7.823027939731933e-10 valloss 5.55261919998884e-07\n",
      "6.597255630680365e-09\n",
      "9.42465090097195e-10\n",
      "iter 85 train loss 9.42465090097195e-10 valloss 5.520104195966269e-07\n",
      "8.303698173506291e-09\n",
      "1.1862425962151845e-09\n",
      "iter 86 train loss 1.1862425962151845e-09 valloss 5.549370030166756e-07\n",
      "1.0839186437294757e-08\n",
      "1.5484552053278223e-09\n",
      "iter 87 train loss 1.5484552053278223e-09 valloss 5.511370773092494e-07\n",
      "1.4528122704859925e-08\n",
      "2.075446100694275e-09\n",
      "iter 88 train loss 2.075446100694275e-09 valloss 5.544592340811505e-07\n",
      "1.9744803125831822e-08\n",
      "2.8206861608331177e-09\n",
      "iter 89 train loss 2.8206861608331177e-09 valloss 5.496585799846798e-07\n",
      "2.7068036700939047e-08\n",
      "3.866862385848435e-09\n",
      "iter 90 train loss 3.866862385848435e-09 valloss 5.534554929909064e-07\n",
      "3.0986992527459734e-08\n",
      "4.426713218208533e-09\n",
      "iter 91 train loss 4.426713218208533e-09 valloss 5.470769792736974e-07\n",
      "3.6646575551912974e-08\n",
      "5.23522507884471e-09\n",
      "iter 92 train loss 5.23522507884471e-09 valloss 5.515706789083197e-07\n",
      "4.0616878749233365e-08\n",
      "5.8024112498904805e-09\n",
      "iter 93 train loss 5.8024112498904805e-09 valloss 5.437116215034621e-07\n",
      "4.071740988820238e-08\n",
      "5.816772841171769e-09\n",
      "iter 94 train loss 5.816772841171769e-09 valloss 5.484754979079298e-07\n",
      "3.634057677004421e-08\n",
      "5.191510967149173e-09\n",
      "iter 95 train loss 5.191510967149173e-09 valloss 5.408067522694182e-07\n",
      "2.9026169912071964e-08\n",
      "4.1465957017245665e-09\n",
      "iter 96 train loss 4.1465957017245665e-09 valloss 5.448640081340272e-07\n",
      "2.268200205435278e-08\n",
      "3.2402860077646825e-09\n",
      "iter 97 train loss 3.2402860077646825e-09 valloss 5.393009701037954e-07\n",
      "2.0151810886659405e-08\n",
      "2.878830126665629e-09\n",
      "iter 98 train loss 2.878830126665629e-09 valloss 5.420264983513334e-07\n",
      "2.20360263369912e-08\n",
      "3.148003762427314e-09\n",
      "iter 99 train loss 3.148003762427314e-09 valloss 5.38248343673331e-07\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "train_loss_lst=np.zeros(n_iterations)\n",
    "val_loss_lst=np.zeros(n_iterations)\n",
    "\n",
    "n_batch=int(len(X_train1)/batch_size)\n",
    "#print(n_batch)\n",
    "for i in range(n_iterations):\n",
    "    train_loss=0\n",
    "    for j in range(n_batch):\n",
    "        batch_start_index=j*batch_size\n",
    "        X_batch_1=X_train1[batch_start_index:batch_start_index+batch_size]\n",
    "        X_batch_2=X_train2[batch_start_index:batch_start_index+batch_size]\n",
    "\n",
    "        out1=mlp(X_batch_1)\n",
    "        out2=mlp(X_batch_2)\n",
    "\n",
    "        batch_loss=criterion(out1,out2)\n",
    "        #print(batch_loss)\n",
    "\n",
    "        train_loss+=batch_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    ave_train_loss=train_loss.item()/n_batch\n",
    "    print(train_loss.item())\n",
    "    print(ave_train_loss)\n",
    "    out_val_1=mlp(X_val1)\n",
    "    out_val_2=mlp(X_val2)\n",
    "    val_loss=criterion(out_val_1,out_val_2)\n",
    "    print('iter',i,'train loss',ave_train_loss,'valloss',val_loss.item())\n",
    "    train_loss_lst[i]=ave_train_loss\n",
    "    val_loss_lst[i]=val_loss\n",
    "\n",
    "    \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "66f1de03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the training versus validation\n",
    "import matplotlib.pyplot as plt\n",
    "x_axis=np.arange(n_iterations)\n",
    "\n",
    "fig,ax1=plt.subplots()\n",
    "\n",
    "color='tab:red'\n",
    "ax1.set_xlabel('num iterations')\n",
    "ax1.set_ylabel=('training loss')\n",
    "ax1.plot(x_axis,train_loss_lst,color=color)\n",
    "ax1.tick_params(axis='y',labelcolor=color)\n",
    "\n",
    "ax2=ax1.twinx()\n",
    "\n",
    "color='tab:blue'\n",
    "ax2.set_ylabel('validation loss')\n",
    "ax2.plot(x_axis,val_loss_lst/1000)\n",
    "ax2.tick_params(axis='y',labelcolor=color)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "311784a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 128])\n",
      "tensor([-0.0605,  0.0388, -0.0483,  0.0157, -0.0278, -0.0248, -0.0173,  0.0291,\n",
      "         0.0214,  0.0038,  0.0176, -0.0658, -0.0472, -0.0471,  0.0116,  0.0102,\n",
      "         0.1105,  0.0225,  0.0371,  0.0116,  0.0080,  0.0013,  0.0028,  0.0455,\n",
      "        -0.0586,  0.0453, -0.0266,  0.0494,  0.0494, -0.0741,  0.1052,  0.0100,\n",
      "         0.0113, -0.0079, -0.0659, -0.0216,  0.0601, -0.0346,  0.1264, -0.0690,\n",
      "        -0.0857,  0.0145, -0.0275,  0.0873,  0.0777, -0.0677, -0.0490,  0.0125,\n",
      "         0.0282, -0.0456,  0.0429,  0.0081,  0.0351, -0.0012,  0.0091, -0.0213,\n",
      "        -0.0038, -0.0137,  0.0410,  0.0133,  0.0041, -0.0289,  0.0193, -0.0170,\n",
      "        -0.0068, -0.0754,  0.0651, -0.0156, -0.0428,  0.1056,  0.0231,  0.0038,\n",
      "        -0.0466,  0.0465, -0.1112, -0.0204,  0.0413,  0.0485,  0.0229, -0.1112,\n",
      "        -0.0271,  0.0324, -0.0264,  0.0168, -0.0403, -0.0342,  0.0198, -0.0515,\n",
      "         0.0701, -0.0126,  0.0956,  0.0557,  0.0604,  0.0428, -0.0315,  0.0306,\n",
      "        -0.0329,  0.0247, -0.0253, -0.0146, -0.0205, -0.0164, -0.0708, -0.0306,\n",
      "        -0.0931, -0.0384,  0.0302, -0.0231,  0.0054,  0.0371, -0.0035,  0.1144,\n",
      "        -0.0251,  0.0194,  0.0810, -0.0263,  0.0332, -0.0184,  0.0005,  0.0770,\n",
      "         0.0482,  0.0130,  0.0132, -0.0115, -0.0421,  0.0225, -0.0213,  0.0526],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#get the encoded outputs throught the projection head\n",
    "mlp.eval()\n",
    "encoded_prompt_tensor=mlp(output_tensor)\n",
    "print(encoded_prompt_tensor.shape)\n",
    "print(encoded_prompt_tensor[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
